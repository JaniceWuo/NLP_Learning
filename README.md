# NLP_Learning

## ELMO模型
首先要知道由`word2vec`生成的词向量，一个词只有一种词向量表示，但是通常情况下，无论英文还是中文，很多词都有多种含义。	
ELMo模型的作者利用语言模型来获得一个上下文相关的预训练表示(利用的是双向LSTM)。  与传统词向量不同的是，ELMo利用预训练
好的双向语言模型可以得到上下文依赖的当前词表示(`对于不同上下文，同样的词表示不一样`)。    

什么是`预训练`：本来神经网络都是先进行参数随机初始化，然后通过BP算法利用其它优化算法去优化模型参数。而预训练的思想是，
模型参数不再是随机初始化，而是先由一个任务进行训练得到一套模型的参数，然后用这套参数对模型进行初始化，再进行训练。    

## 元学习（Meta Learning）
是研究如何让神经网络很好的利用以往的知识，根据新任务调整自己。
